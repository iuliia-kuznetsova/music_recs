README

This document describes stages of Yandex Music recommendation system project

1. Data Loading Stage

Data Preprocessing Stage 

the data preprocessing stage for the music recommender project.
It explains every transformation applied to the raw items_df (track metadata) and the rationale,
so the resulting catalogs are clean, deduplicated, canonicalized and ready for downstream models
(popularity, ALS, item-similarity, ranking).

Input

items_df with columns (example):

track_id, track_name, artist_id, artist_name, album_id, album_name, genre_id, genre_name


(Any additional raw metadata is preserved but not required for the core pipeline.)

Output

Final canonical catalogs and tables:

tracks_catalog_clean:
  track_id (canonical)
  track_clean
  track_group_id
  artist_id (canonical)
  album_id (canonical)
  genre_id (canonical)

artists_catalog_clean:
  artist_id (canonical)
  artist_clean

albums_catalog_clean:
  album_id (canonical)
  album_clean
  artist_id (canonical)

genres_catalog_clean:
  genre_id (canonical)
  genre_clean


All *_clean names are normalized; track_group_id links all versions of the same song family.

Prerequisites

Python environment with Polars (recommended), rapidfuzz (optional), networkx (for graph components), and python-dotenv if using .env.

Raw dataset loaded into items_df.

(Optional) audio fingerprints / lyrics if available — improve grouping quality.

High-level summary of steps

Basic normalization

Remove noise/version tokens

Canonicalize artists, albums, tracks, genres

Build ID mapping tables (original ID → canonical ID)

Create cleaned name fields

Generate fingerprints/tokens for titles

Build similarity graph (candidate edges)

Compute connected components → assign track_group_id

Produce final canonical catalogs

Validation, dedupe, storage

Detailed step-by-step

STEP 0 — Basic normalization

Convert relevant text fields to lowercase.

Trim leading/trailing whitespace and collapse multiple spaces.

Normalize unicode (NFKD), replace non-breaking spaces with normal spaces.

Fill null/empty strings where necessary with a placeholder ('unknown').
Why: Removes trivial differences that would break deduplication and matching.

STEP 1 — Remove noise/version tokens from track names

Remove tokens such as:
live, remix, remastered, version, extended, edit, radio, acoustic, cover, instrumental, feat., ft.

Remove bracketed/parenthetical text that often contains version details.

Collapse repeated whitespace and strip.

Create track_name_clean (base title for grouping).
Why: Version tokens split the same underlying composition into many strings; cleaning focuses on base title.

STEP 2 — Normalize artist and album names

artist_name_clean, album_name_clean: lowercase, strip, collapse spaces, remove control characters.

Do not merge different artists unless they clearly represent the same entity (dedup later).
Why: Consistent artist/album strings improve joins and canonicalization.

STEP 3 — Create canonical entity tables (dedup)

For each entity (artist, album, track, genre):

Group by the normalized name(s) and compute a canonical ID (e.g., min(original_id) or new UUID).

Build deduped tables:

artists_dedup (artist_clean → artist_id_canonical)

albums_dedup (album_clean (+ artist) → album_id_canonical)

tracks_dedup (track_clean (+ artist) → track_id_canonical)

genres_dedup (genre_clean → genre_id_canonical)

Keep canonical cleaned names alongside canonical IDs.
Why: Raw source may contain multiple IDs for the same real-world entity.

STEP 4 — Build ID mapping tables

For each original catalog, join with its dedup table to map every original ID to a canonical ID:

artist_id_map: original_artist_id → artist_id_canonical

album_id_map: original_album_id → album_id_canonical

track_id_map: original_track_id → track_id_canonical

genre_id_map: original_genre_id → genre_id_canonical

These maps allow rewriting the entire items_df using canonical IDs.
Why: Tracks in items_df or events_df may reference any original ID — mapping ensures consistent IDs.

STEP 5 — Create cleaned name fields & fingerprints

Create track_clean, artist_clean, album_clean, genre_clean — canonical readable strings.

Create a name fingerprint for track title grouping:

remove punctuation, digits optional, tokenize, sort tokens, join → name_fingerprint

Extract token features:

tokens, token_count, first_token, last_token
Why: Fingerprints and token features are robust cues for grouping similar titles.

STEP 6 — Build candidate edges for graph

Edges are candidate equivalences between two track_ids. Add edges under rules:

Same fingerprint → strong edge.

High token Jaccard (e.g., ≥ 0.8) → likely same.

Small Levenshtein distance (e.g., ≤ 3) between cleaned names → possible match.

(Optional) Audio fingerprint / lyrics match → strongest edge.

(Optional) NLP name similarity (embedding cosine) > threshold → add edge.

Collect all candidate edges. Use conservative thresholds to avoid false merges.
Why: Graph edges encode multiple matching signals and make grouping robust.

STEP 7 — Graph connected components → track_group_id

Build an undirected graph where nodes = track_id and edges = candidate links.

Compute connected components (each component is a group).

Assign track_group_id (for example, min(track_id) or new sequential ID) to all nodes in the component.
Why: Connected components aggregate transitive similarity (A≈B and B≈C ⇒ A,B,C grouped).

STEP 8 — Build final canonical items table

Join items_df with all canonical id maps and cleaned names:

Replace original IDs with canonical IDs.

Keep track_id_canonical, track_clean, track_group_id, artist_id_canonical, artist_clean, album_id_canonical, album_clean, genre_id_canonical, genre_clean.

Select and reorder columns into tracks_catalog_clean.

Remove exact duplicates (rows where all selected columns are equal).
Why: Produce the final clean catalog for downstream modeling.

STEP 9 — Validation and quality checks

Check for missing canonical IDs or cleaned names; fill or drop as appropriate.

Verify uniqueness constraints (e.g., track_id_canonical should be unique in tracks catalog).

Check group sizes distribution — spot overly large groups (false merges).

Randomly sample groups and manually inspect to detect systematic errors.
Why: Prevent model problems created by mis-groupings or missing data.

STEP 10 — Storage and provenance

Save outputs as Parquet with schema and versioned path (e.g., s3://<bucket>/catalogs/items_catalog/v=YYYYMMDD/items.parquet).

Record transformation metadata (script hash, parameters, thresholds, date) in pipeline logs or metadata store.
Why: Reproducibility, rollback, and auditability.

Practical tips and caveats

Conservative grouping: prefer false negatives (missed group merges) over false positives (wrong merges). Wrong merges can damage recommendations.

Threshold tuning: thresholds for Jaccard / Levenshtein / embedding similarity must be tuned on your dataset.

Iterative manual review: run grouping, sample largest components, and fix rules incrementally.

Use audio/lyrics if available: they dramatically improve grouping quality.

Store intermediate artifacts: keep maps and fingerprints for debugging.

Productionization: run canonicalization + grouping as a batch job; persist results and re-run periodically or when new catalogs arrive.

Backwards compatibility: if you change mapping rules, consider mapping old canonical ids to new ones (migration).

Performance: graph construction over millions of nodes requires blocking (candidate generation) — use fingerprint buckets, n-gram blocking, or LSH to reduce pairwise comparisons.

Appendix: common regexes & token patterns

Remove parentheses/brackets: \s*[\(\[].*?[\)\]]\s*

Remove version words: \b(live|remix|remastered|version|edit|acoustic|instrumental|feat\.|ft\.)\b

Collapse whitespace: \s+ → ' '

Unicode normalization: NFKD → remove diacritics

Example outputs you should see

tracks_catalog_clean shape: (N_tracks_canonical, columns)

artists_catalog_clean shape: (N_artists_canonical, columns)

group distribution: histogram showing many small groups and a long tail (popular songs with many versions)

No null canonical IDs (or controlled small number flagged for manual fix)

Contact & change log

Author: [Your name/project]

Version: 1.0

Last updated: YYYY-MM-DD

Notes: store pipeline parameters and thresholds next to documentation for future reference.

End of README — Data Preprocessing Stage.

You said:
translate it to russian
ChatGPT said:
README — Этап предварительной обработки данных (пошагово)
Цель

Этот документ описывает этап предварительной обработки данных для проекта музыкального рекомендателя.
Он объясняет все преобразования, применяемые к исходному items_df (метаданные треков), и обоснование этих шагов,
чтобы полученные каталоги были очищены, дедуплицированы, канонизированы и готовы для моделей (популярность, ALS, похожие треки, ранжирование).

Входные данные

items_df с колонками (пример):

track_id, track_name, artist_id, artist_name, album_id, album_name, genre_id, genre_name


(Любые дополнительные метаданные сохраняются, но для основной обработки не обязательны.)

Выходные данные

Окончательные канонические каталоги и таблицы:

tracks_catalog_clean:
  track_id (канонический)
  track_clean
  track_group_id
  artist_id (канонический)
  album_id (канонический)
  genre_id (канонический)

artists_catalog_clean:
  artist_id (канонический)
  artist_clean

albums_catalog_clean:
  album_id (канонический)
  album_clean
  artist_id (канонический)

genres_catalog_clean:
  genre_id (канонический)
  genre_clean


Все поля *_clean — нормализованные названия; track_group_id объединяет все версии одной композиции.

Предварительные требования

Python окружение с Polars (рекомендуется), rapidfuzz (опционально), networkx (для графов), python-dotenv (если используется .env).

Исходный датасет загружен в items_df.

(Опционально) аудиофингерпринты или тексты песен — улучшают качество группировки.

Краткое описание этапов

Базовая нормализация

Удаление шумовых / версионных токенов

Канонизация артистов, альбомов, треков, жанров

Создание таблиц отображения ID (оригинальный ID → канонический ID)

Создание очищенных полей с именами

Генерация "отпечатков" названий и токенов

Построение графа схожести треков (candidate edges)

Вычисление компонент связности → присвоение track_group_id

Формирование окончательных канонических каталогов

Валидация, дедупликация, сохранение

Пошаговое описание

ШАГ 0 — Базовая нормализация

Преобразование текстовых полей в нижний регистр.

Удаление лишних пробелов, нормализация Unicode (NFKD), замена неразрывных пробелов на обычные.

Заполнение пустых значений плейсхолдером 'unknown'.
Почему: Устраняет тривиальные различия, которые мешают дедупликации и сравнению.

ШАГ 1 — Удаление шумовых / версионных токенов

Удаление токенов вроде:
live, remix, remastered, version, extended, edit, radio, acoustic, cover, instrumental, feat., ft.

Удаление скобок и текста в них, часто содержащих информацию о версии.

Создание track_name_clean (базовое название для группировки).
Почему: Версии одного трека могут создавать множество строк; очистка фокусируется на базовом названии.

ШАГ 2 — Нормализация артистов и альбомов

artist_name_clean, album_name_clean: lowercase, strip, удаление управляющих символов.

Не объединяем разные артисты без явной уверенности.
Почему: Консистентные строки артистов/альбомов улучшают объединение и канонизацию.

ШАГ 3 — Создание канонических таблиц (dedup)

Для каждого объекта (артист, альбом, трек, жанр):

Группируем по нормализованному имени и вычисляем канонический ID (например, min(original_id) или новый UUID).

Дедуплицируем таблицы:

artists_dedup (artist_clean → artist_id_canonical)

albums_dedup (album_clean (+ artist) → album_id_canonical)

tracks_dedup (track_clean (+ artist) → track_id_canonical)

genres_dedup (genre_clean → genre_id_canonical)

Храним каноническое имя вместе с ID.
Почему: В исходных данных может быть несколько ID для одной сущности.

ШАГ 4 — Создание таблиц отображения ID

Для каждой сущности создаем отображение:

artist_id_map: original_artist_id → artist_id_canonical

album_id_map: original_album_id → album_id_canonical

track_id_map: original_track_id → track_id_canonical

genre_id_map: original_genre_id → genre_id_canonical

Позволяет переписать все items_df каноническими ID.
Почему: В событиях и items_df могут использоваться любые исходные ID.

ШАГ 5 — Создание очищенных имен и отпечатков

Поля: track_clean, artist_clean, album_clean, genre_clean.

Создание отпечатка названия:

Удаление пунктуации, токенизация, сортировка токенов → name_fingerprint.

Извлечение признаков токенов:

tokens, token_count, first_token, last_token.
Почему: Отпечатки и токены помогают надежно группировать похожие названия.

ШАГ 6 — Построение candidate edges

Узлы графа = track_id, ребра = возможные совпадения:

Одинаковые fingerprints → сильное ребро.

Высокое пересечение токенов (Jaccard ≥ 0.8) → вероятное совпадение.

Малое расстояние Левенштейна (≤3) → возможное совпадение.

(Опционально) совпадение аудиофингерпринтов/текста → сильное ребро.

(Опционально) схожесть эмбеддингов > порог → добавить ребро.
Почему: Ребра графа объединяют различные сигналы сходства.

ШАГ 7 — Компоненты связности → track_group_id

Построение неориентированного графа, вычисление компонент связности.

Присвоение track_group_id (например, минимальный track_id в компоненте).
Почему: Транзитивное объединение треков (A≈B, B≈C ⇒ A,B,C в одной группе).

ШАГ 8 — Формирование окончательного каталога

Объединение items_df с картами канонических ID и очищенными именами.

Выбор и упорядочение колонок:

track_id_canonical, track_clean, track_group_id,
artist_id_canonical, artist_clean,
album_id_canonical, album_clean,
genre_id_canonical, genre_clean


Удаление полных дубликатов строк.
Почему: Получение окончательного чистого каталога для моделей.

ШАГ 9 — Валидация

Проверка на пропуски в канонических ID и именах.

Проверка уникальности (например, track_id_canonical уникален в треках).

Анализ распределения размеров групп, ручная проверка больших групп.
Почему: Предотвращение проблем в моделях из-за неправильных объединений или пропусков.

ШАГ 10 — Сохранение и ведение истории

Сохранение в Parquet с версией и схемой:

s3://<bucket>/catalogs/items_catalog/v=YYYYMMDD/items.parquet


Логирование параметров, порогов, даты.
Почему: Воспроизводимость, откат, аудит.

Советы и предостережения

Консервативная группировка: лучше пропустить слияние (false negative), чем объединить разные треки (false positive).

Тонкая настройка порогов: Jaccard, Левенштейн, эмбеддинги.

Итеративная проверка: случайные выборки больших компонентов.

Использовать аудио/тексты: заметно улучшает группировку.

Сохранять промежуточные артефакты: карты и отпечатки для отладки.

Производительность: граф на миллионах узлов требует блокирования (fingerprint buckets, n-grams, LSH).

Приложение: регулярные выражения и токены

Удаление скобок: \s*[\(\[].*?[\)\]]\s*

Удаление версионных слов: \b(live|remix|remastered|version|edit|acoustic|instrumental|feat\.|ft\.)\b

Сведение пробелов: \s+ → ' '

Нормализация Unicode: NFKD → удаление диакритов

Пример ожидаемых результатов

tracks_catalog_clean — (N_tracks_canonical, колонки)

artists_catalog_clean — (N_artists_canonical, колонки)

Гистограмма распределения групп: много маленьких групп, длинный хвост (популярные треки с множеством версий)

Нет пропущенных канонических ID (или небольшое количество для ручной проверки)

Контакты и история изменений

Автор: [Ваше имя / проект]

Версия: 1.0

Последнее обновление: YYYY-MM-DD

Примечания: хранить параметры и пороги рядом с документацией для будущих проверок.