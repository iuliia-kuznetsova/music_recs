{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4095ae4-7294-4b28-853e-88d235002c97",
   "metadata": {},
   "source": [
    "# Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2318d2-9df8-4911-915e-15b725c44f8a",
   "metadata": {},
   "source": [
    "Загружаем библиотеки необходимые для выполнения кода ноутбука."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4ab1c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d04e7-1b0b-4e4a-9ddf-4526d7fef119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "#import calendar\n",
    "import joblib\n",
    "#import s3fs\n",
    "import gc\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf14d14",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d99d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random state for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "datasets = {\n",
    "    'tracks.parquet': os.getenv('RAW_URL_TRACKS'),\n",
    "    'catalog_names.parquet': os.getenv('RAW_URL_CATALOG_NAMES'),\n",
    "    'interactions.parquet': os.getenv('RAW_URL_INTERACTIONS'),\n",
    "}\n",
    "\n",
    "raw_dir = os.getenv('RAW_DATA_DIR', '../data/raw')\n",
    "preprocessed_dir = os.getenv('PREPROCESSED_DATA_DIR', '../data/preprocessed')\n",
    "encoder_dir = os.getenv('ENCODERS_DIR', '../encoders')\n",
    "\n",
    "s3_bucket = os.getenv('S3_BUCKET_NAME')\n",
    "s3_prefix = os.getenv('S3_PREFIX', 'recsys/data/')\n",
    "s3_region = os.getenv('S3_REGION', 'us-east-1')\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80fbc5-b660-4fac-8fbb-a5cae77313b3",
   "metadata": {},
   "source": [
    "# === ЭТАП 1 ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263a8b3-fe99-4204-8a2e-105182792c11",
   "metadata": {},
   "source": [
    "# Загрузка первичных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54a6a5-1656-4e3c-99d1-49dc39451d33",
   "metadata": {},
   "source": [
    "Загружаем первичные данные из файлов:\n",
    "- tracks.parquet\n",
    "- catalog_names.parquet\n",
    "- interactions.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b8961-3f35-4e58-9d6b-3e2dbd2c4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Download datasets and save locally ---------- #\n",
    "# Create directory\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "\n",
    "# Download and save each dataset\n",
    "for filename, url in datasets.items():\n",
    "    save_path = os.path.join(raw_dir, filename)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with open(save_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f'Saved {filename} to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a595bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load datasets ---------- #\n",
    "tracks = pl.read_parquet(os.path.join(raw_dir, 'tracks.parquet'))\n",
    "catalog_names = pl.read_parquet(os.path.join(raw_dir, 'catalog_names.parquet'))\n",
    "interactions = pl.read_parquet(os.path.join(raw_dir, 'interactions.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2a1f7-a05f-4f39-af90-5f4018aa6f9d",
   "metadata": {},
   "source": [
    "# Обзор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a85307-896c-4fac-9fcf-f0dffa90889e",
   "metadata": {},
   "source": [
    "Проверяем данные, есть ли с ними явные проблемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Check data summary ---------- #\n",
    "def data_summary(df: pd.DataFrame, name: str):\n",
    "    '''\n",
    "        Display a quick overview of a DataFrame.\n",
    "    '''\n",
    "\n",
    "    print(f'\\n===== {name.upper()} =====')  \n",
    "  \n",
    "    # Sample rows\n",
    "    print('\\nSample rows:')\n",
    "    display(df.head())\n",
    "\n",
    "    # Shape\n",
    "    rows, cols = df.shape\n",
    "    print(f'\\nShape: {rows} rows x {cols} columns')\n",
    "    \n",
    "    # Data info\n",
    "    print('\\nSummary for numeric columns:')\n",
    "    print(df.describe())\n",
    "   \n",
    "    # Unique values (column-wise, skip if error occurs)\n",
    "    print('\\nUnique values (for each column):')\n",
    "    try:\n",
    "        for col in df.columns:\n",
    "            print(f'\\nColumn: {col}')\n",
    "            print(df[col].value_counts())\n",
    "    except Exception as e:\n",
    "        print(f'Skipped value_counts due to error: {e}')\n",
    "    \n",
    "    # Missing values\n",
    "    print('\\nMissing values:')\n",
    "    print(df.null_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffa4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary(tracks, 'tracks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd2e2eb-3bec-4ce1-87ac-232bab8bc0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary(catalog_names, 'catalog_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b06299",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary(interactions, 'interactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba0a88",
   "metadata": {},
   "source": [
    "### Main takeaways\n",
    "1. Tracs dataframe contains lists instead of scalar values. This can cause several problems:\n",
    "- Unable to get insights on data;\n",
    "Counting, merging, or joining on list columns is tricky.\n",
    "- Missing values are hidden;\n",
    "df.isna().sum() can’t detect empty lists, so there might be tracks with no genres or artists but they look as not missing values.\n",
    "- Hard to work with for ML models.\n",
    "Most algorithms expect scalar values, not lists.\n",
    "Thus, it's necessary to explode the lists to get a dataframe with one row per track-per-item (artist, genre, album).\n",
    "\n",
    "2. Catalog_names dataframe is in a format where everything (tracks, albums, artists, genres) is stacked in one column, and the type column tells what each row represents. This format isn't convenient for futher work. Thus, it's necessary to split catalog_names into several dataframes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
